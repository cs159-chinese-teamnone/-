import cv2
import numpy as np
import pandas as pd
from PIL import Image #先安装pillow包，如error则先升级numpy再安装
from keras import backend as K
from keras.preprocessing.image import load_img, img_to_array
from keras.applications import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.layers import Input
from scipy.optimize import fmin_l_bfgs_b
import time
import random
import pygame
pygame.init()
# 人脸检测器 定位haarcascade_frontalface_alt.xml
faceCascade = cv2.CascadeClassifier("/Users/neolee/anaconda3/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_alt.xml")
def detectFaces(image_name):
  img = cv2.imread(image_name)
  #定位haarcascade_frontalface_default.xml
  face_cascade = cv2.CascadeClassifier("/Users/neolee/anaconda3/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml")
  if img.ndim == 3:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  else:
    gray = img #if语句：如果img维度为3，说明不是灰度图，先转化为灰度图gray，如果不为3，也就是2，原图就是灰度图
 
  faces = face_cascade.detectMultiScale(gray, 1.2, 5)#1.2和5是特征的最小、最大检测窗口，它改变检测结果也会改变
  result = []
  for (x,y,width,height) in faces:
    result.append((x,y,x+width,y+height))
  return result
if __name__ == '__main__':
    result=detectFaces('1.jpg')
if len(result)>0:
    # 笑脸检测器
    smileCascade = cv2.CascadeClassifier("/Users/neolee/anaconda3/lib/python3.6/site-packages/cv2/data/haarcascade_smile.xml")
    img = cv2.imread("1.jpg")
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 首先检测人脸，返回的是框住人脸的矩形框
    faces = faceCascade.detectMultiScale(gray,1.3,5,minSize=(55,55))
    # 画出每一个人脸，提取出人脸所在区域
    for (x, y, w, h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        # 对人脸进行笑脸检测
        smile = smileCascade.detectMultiScale(
            roi_gray,
            scaleFactor= 1.16,
            minNeighbors=35,
            minSize=(25, 25)
            )
        # 检测笑脸并打上标签
        result=[]
        for (x2, y2, w2, h2) in smile:
            result.append((x2,y2,x2+w2,y2+h2))
        if len(result)>0:
            model=['smile1','smile2','smile3']#语句库，可更改
            word=model[random.randint(0,3)]
            cv2.putText(img,word,(x,y-7), 3, 1.2, (0, 255, 0), 2, cv2.LINE_AA)
            cv2.imshow('Smile?', img)
            c = cv2.waitKey(0)
            for event in pygame.event.get():
                if event.type==pygame.KEYDOWN:
                    if event.key==pygame.K_q:
                        pygame.quit()
                    elif event.key==pygame.K_s:
                        cv2.imwrite('smile.jpg',img)
                        pygame.quit()
        #风格迁移
        else:
            #keras风格迁移


            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
            ## Specify paths for 1) content image 2) style image and 3) generated image
            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##

            cImPath = '1.jpg'#（jpg格式图片，原图）
            sImPath = 'fangao.jpg'#（jpg格式图片，风格图）
            genImOutputPath = 'output.jpg'#（输出图片）

            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
            ## Image processing
            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
            targetHeight = 512
            targetWidth = 512
            targetSize = (targetHeight, targetWidth)

            cImageOrig = Image.open(cImPath)
            cImageSizeOrig = cImageOrig.size
            cImage = load_img(path=cImPath, target_size=targetSize)
            cImArr = img_to_array(cImage)
            cImArr = K.variable(preprocess_input(np.expand_dims(cImArr, axis=0)), dtype='float32')
            sImage = load_img(path=sImPath, target_size=targetSize)
            sImArr = img_to_array(sImage)
            sImArr = K.variable(preprocess_input(np.expand_dims(sImArr, axis=0)), dtype='float32')

            gIm0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')
            gIm0 = preprocess_input(np.expand_dims(gIm0, axis=0))

            gImPlaceholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))

            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##
            ## Define loss and helper functions以下代码可不看
            ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~##

            def get_feature_reps(x, layer_names, model):
                featMatrices = []
                for ln in layer_names:
                    selectedLayer = model.get_layer(ln)
                    featRaw = selectedLayer.output
                    featRawShape = K.shape(featRaw).eval(session=tf_session)
                    N_l = featRawShape[-1]
                    M_l = featRawShape[1]*featRawShape[2]
                    featMatrix = K.reshape(featRaw, (M_l, N_l))
                    featMatrix = K.transpose(featMatrix)
                    featMatrices.append(featMatrix)
                return featMatrices

            def get_content_loss(F, P):
                cLoss = 0.5*K.sum(K.square(F - P))
                return cLoss

            def get_Gram_matrix(F):
                G = K.dot(F, K.transpose(F))
                return G

            def get_style_loss(ws, Gs, As):
                sLoss = K.variable(0.)
                for w, G, A in zip(ws, Gs, As):
                    M_l = K.int_shape(G)[1]
                    N_l = K.int_shape(G)[0]
                    G_gram = get_Gram_matrix(G)
                    A_gram = get_Gram_matrix(A)
                    sLoss= sLoss+w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_l**2 * M_l**2)
                return sLoss

            def get_total_loss(gImPlaceholder, alpha=1.0, beta=10000.0):
                F = get_feature_reps(gImPlaceholder, layer_names=[cLayerName], model=gModel)[0]
                Gs = get_feature_reps(gImPlaceholder, layer_names=sLayerNames, model=gModel)
                contentLoss = get_content_loss(F, P)
                styleLoss = get_style_loss(ws, Gs, As)
                totalLoss = alpha*contentLoss + beta*styleLoss
                return totalLoss

            def calculate_loss(gImArr):
                """
                Calculate total loss using K.function
                """
                if gImArr.shape != (1, targetWidth, targetWidth, 3):
                    gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))
                loss_fcn = K.function([gModel.input], [get_total_loss(gModel.input)])
                return loss_fcn([gImArr])[0].astype('float64')
                def get_grad(gImArr):
                    """
                    Calculate the gradient of the loss function with respect to the generated image
                    """
                    if gImArr.shape != (1, targetWidth, targetHeight, 3):
                        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))
                    grad_fcn = K.function([gModel.input], K.gradients(get_total_loss(gModel.input), [gModel.input]))
                    grad = grad_fcn([gImArr])[0].flatten().astype('float64')
                    return grad

                def postprocess_array(x):
                    # Zero-center by mean pixel
                    if x.shape != (targetWidth, targetHeight, 3):
                        x = x.reshape((targetWidth, targetHeight, 3))
                    x[..., 0] =x[..., 0]+103.939
                    x[..., 1] =x[..., 1]+116.779
                    x[..., 2] =x[..., 2]+123.68
                    # 'BGR'->'RGB'
                    x = x[..., ::-1]
                    x = np.clip(x, 0, 255)
                    x = x.astype('uint8')
                    return x

                def reprocess_array(x):
                    x = np.expand_dims(x.astype('float64'), axis=0)
                    x = preprocess_input(x)
                    return x

                def save_original_size(x, target_size=cImageSizeOrig):
                    xIm = Image.fromarray(x)
                    xIm = xIm.resize(target_size)
                    xIm.save(genImOutputPath)
                    return xIm

                tf_session = K.get_session()
                cModel = VGG16(include_top=False, weights='imagenet', input_tensor=cImArr)
                sModel = VGG16(include_top=False, weights='imagenet', input_tensor=sImArr)
                gModel = VGG16(include_top=False, weights='imagenet', input_tensor=gImPlaceholder)
                cLayerName = 'block4_conv2'
                sLayerNames = [
                'block1_conv1',
                'block2_conv1',
                'block3_conv1',
                'block4_conv1',
                #'block5_conv1'
                ]

                P = get_feature_reps(x=cImArr, layer_names=[cLayerName], model=cModel)[0]
                As = get_feature_reps(x=sImArr, layer_names=sLayerNames, model=sModel)
                ws = np.ones(len(sLayerNames))/float(len(sLayerNames))

                iterations = 200
                x_val = gIm0.flatten()
                start = time.time()
                xopt, f_val, info= fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,
                                            maxiter=iterations, disp=True)
                xOut = postprocess_array(xopt)
                xIm = save_original_size(xOut)
                end = time.time() 
else:
    print('无人！')
    break
    


       



